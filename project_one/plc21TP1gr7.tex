\documentclass[11pt,a4paper,times]{report}

\usepackage[utf8]{inputenc}
\usepackage{times}
\usepackage{multirow}
\usepackage{array}
\usepackage[pdftex]{hyperref}
\usepackage{graphicx}
\usepackage{url}
\usepackage{enumerate}
\usepackage{xspace}
\usepackage[portuguese,main=english]{babel}
\usepackage{cite}
\usepackage{listings}
\usepackage{color}
\parindent=0pt
\parskip=2pt
\setlength{\oddsidemargin}{-1cm}
\setlength{\textwidth}{18cm}
\setlength{\headsep}{-1cm}
\setlength{\textheight}{23cm}
\lstset{
	basicstyle=\small, %o tamanho das fontes que são usadas para o código
	numbers=left, % onde colocar a numeração da linha
	numberstyle=\tiny, %o tamanho das fontes que são usadas para a numeração da linha
	numbersep=5pt, %distancia entre a numeração da linha e o codigo
	breaklines=true, %define quebra automática de linha
    frame=tB,  % caixa a volta do codigo
	mathescape=true, %habilita o modo matemático
	escapeinside={(*@}{@*)} % se escrever isto  aceita tudo o que esta dentro das marcas e nao altera
}
\lstdefinestyle{custompy}{
  belowcaptionskip=1\baselineskip,
  breaklines=true,
  frame=tB,
  xleftmargin=\parindent,
  language=Python,
  showstringspaces=false,
  basicstyle=\footnotesize\ttfamily,
  backgroundcolor=\color{white},
  keywordstyle=\bfseries\color{red},
  commentstyle=\itshape\color{blue},
  identifierstyle=\color{black},
  stringstyle=\color{green},
}
\def\CSV{Comma-Separated Values\xspace}
\def\JSON{JavaScript Object Notation\xspace}
\def\XLS{Excel Binary File Format\xspace}
\def\JS{JavaScript\xspace}

\title{Processamento de Linguagens e Compiladores (3º Ano LCC)\\ 
      \textbf{Project 1} \\ Project Report
      }
\date{\today}
\author{Bruno Dias da Gião\\ A96544 \and Maria Filipa Rodrigues \\ A97536}

\begin{document}
\maketitle

\selectlanguage{portuguese}
\begin{abstract}
Um ficheiro do tipo \textit{\CSV} é um formato de extrema importância, 
isto devido ao facto de ser texto plano, no entanto, as suas aplicações
são limitadas, motivando a escrita de um programa em Python que, 
usando expressões regulares, converte qualquer ficheiro deste tipo para 
um ficheiro do tipo \textit{\JSON}, que, devido à sua legibilidade e 
capacidade de ser \textit{parsed} diretamente para um objeto de 
JavaScript ou de ser diretamente usado em contextos web, tem 
praticalidade mais acrescida. Isto, claro, representa uma conversão 
extremamente trivial e, devido à natureza de CSV, pode até permitir a
conversão de qualquer ficheiro variante de \XLS para um ficheiro JSON.
\end{abstract}
\selectlanguage{english}
\begin{abstract}
A \CSV file is an extremely important file type, this is due to it being 
plain text, however its applications are limited, motivating us to 
write a program in Python that, using regular expressions, 
converts any file with this file format into a \JSON file, which has more
practical uses for both it's readability and being parsed into JavaScript
Objects or be used directly into a website context. This, of course, has 
an extremely trivial conversion and due to CSV's nature, might even
allow for the conversion of any XLS file variation into JSON.
\end{abstract}

\tableofcontents

\chapter{Report} \label{chap:report}
\section{Introduction} \label{intro} 
\subsection{CSV to JSON conversion}
\subsubsection*{Introduction to the Report} This report is structured by 
the literate component itself \ref{chap:report} and by the code component
which shall contain all the code used for this project \ref{chap:code}.
\\
Within the literate component we introduce the project with a historical
background of the file formats being studied, why we believe this project
is important, the original premise of the exercise and what can be
done to expand it in a productive way that complements what is lectured
in this class.
\\
After this introduction, we move on towards implementations, design 
decisions and the finer technical and theoretical aspects of the project
in the methodology section \ref{methodology}. Here we go into detail on 
regular expressions, the re module, how the properties of CSV were used
to manipulate the file via regex and how the JSON file was created.
In this very section there is also a segment dedicated to exemplifying 
the tests used to verify the proper functioning of the program.
\\
The last section of the this chapter is the conclusion \ref{conclusion}
where a brief summary of the results are gathered and insight is given on
what could've been done and how this project can be expanded on.
\\
Finally, we have the code component of the report which will contain all
the code used during this project.
\\
As standard for a report, the last pages are dedicated towards the
bibliography.

\subsubsection*{Historical background of CSV and XLS}CSV, or \CSV, is a
well known file type for data storage, much like XL, or \XLS, files in 
the sense that both represent tabular data, however, the major difference
is that CSV is a plain text file, each line representing a row and each 
comma a column, thus, anything between commas, a cell. CSV has a great 
historical background as it predates the personal computer being 
supported by the IBM Fortran under `OS/360' in 1972. \cite{FORTRANCSV}
The file type name CSV itself, however, only came into existence in 1983.
\\
XLS however only came into existence in 1987 with Excel's first Windows 
version, that being Excel 2. \cite{EXCELOR} In 2007, however, XLS was deprecated and the
use of XML versions of Excel spreadsheets was promoted, thus
introducing XLSX.
\subsubsection*{Historical background of JavaScript and JSON}JavaScript
is a programming language famous for being one of the only capable of
being used on the World Wide Web on the client side for web-page behaviour.
It was first released in 1995 as an attempt to embed Java and Scheme
(a very popular LISP dialect), but was decided it was best to create
a new language in itself with syntax more similar to Java than to Scheme.
\\
Most importantly for this report is a specific data structure included in 
JavaScript, `objects', which are synonymous to associative arrays
in other languages, thus, in the early 2000s, out of a need for stateless,
real time server-to-browser communication protocols without Flash or
Java applets, JSON files were created, these are code independent,
as almost any language can parse it, but due to it's inspired syntax from
JavaScript, it's is most popular for use with this programming language.

\subsubsection*{Importance of this project}Given the historical and
practical significance of these three file formats, it is understandable
how important it is to have a program that can seamlessly convert a CSV
file into a JSON file, or, perhaps even, a program that converts a XLS 
file into a CSV file and thus allow for the previous program to convert 
it into JSON, that is what we aim to achieve with this project.
\\
Again, considering how readable and easy to produce CSV files are,
combined with how practical JSON files are, we can, from a plain text,
send data in the text file from a server to a client, or display it on a 
web page.


\subsubsection*{Background of the Project}In this class, it was asked to
solve one of five questions, the fifth, the one we chose, is the 
conversion of a modified CSV format that includes lists and aggregation 
functions into a JSON file using regular expressions. These lists can be
of fixed size N or a size between N and M, the aggregation functions were
left at the students criteria.

\subsubsection*{Expansions of the Project}Considering XLS is nothing more
than a zipped file containing XML files, this conversion should be 
trivial provided the `renaming' to the zipped file can be done, after
which, theoretically, we should only need to find the cell data we need
in the files inside the `xl' directory.
\\
Indeed, this project only requires the conversion of a modified CSV into
JSON, however, considering the properties CSV and XLS share, it seemed
wise to at least explore the possibilities for the previously
mentioned conversion, XLS variations into CSV.
\\
In reality, this endeavour is not as easy as it might appear due to
how ambiguous excel cell data is in the xml files that constitute it,
however it is still an interesting topic that, despite it there being a
functionality in Excel itself, a Python script that could convert XLS to 
CSV and perform the script created for the project would be of 
great importance.

\section{Methodology} \label{methodology}
\subsection{Theoretical Background} \label{theory}
\subsubsection*{Regular Expressions}Regular expression are an essential
component of Computer Science, both theoretical and practical, this
because they were originated in the context of Automaton Theory and Formal Languages.   
Because regular expressions represent regular languages, we can use 
these for `pattern matching', allowing an user to easily find the first 
instance or all instances of a given pattern, or instead to replace one,
all instances or a given amount of matches, this allows for ease of use
for various actions such as, converting file types correctly, converting
from a formal language into machine language, sorting, managing data,
and much more.
\subsubsection*{Python's re module}In order to work with regular
expressions, Python has a built-in module called `re' which allows the
use of some powerful functions that take a raw string containing a
regular expression, a string to be analysed and produce, very
efficiently, the desired result. The most important functions that will 
be used in this project are:
\begin{itemize}
    \item{\verb|re.search(regex,string)|}
    \item{\verb|re.split(regex,string)|}
    \item{\verb|re.sub(regex,regex,string)|}
    \item{\verb|re.subn(regex,regex,string,count=n)|}
\end{itemize}
There is an increased focus on the sub and split functions as they are
the most important functions to be used in this project, carrying into
both the parsing of the file, creation of lists, and into the creation of the JSON
file itself.
\subsection{Practical component} \label{practice}

\subsubsection*{Opening a CSV file} When the program is executed, it will
ask the user to input the name of a valid CSV file. \\ In order to
enforce such a prerequisite some defensive code was employed, performing
the following instructions
\begin{enumerate}
    \item{Asks the User for an input that ends in .csv}
    \item{Uses a regular expression - 
        \begin{verbatim}
            ([A-Za-z0-9\_\-]+)\.csv
        \end{verbatim}
    This makes sure that the input refers to a CSV file.}
    \item{Saves the first group from the matched pattern}
    \item{Opens the file, thus checking if it exists}
\end{enumerate}

\subsubsection*{Finding all Lists} Finding lists and parsing them so they
are ready to be worked with, might be one the aspects of this project,
that, alongside the manipulation itself of the lists and the attempt at
converting XL files to CSV that required more work than most. \\
In order to do so however the following structure was adhered to:
\begin{enumerate}
    \item{Uses a regular expression - 
        \begin{verbatim}
        ([A-Za-z0-9 \_\-]+){([0-9]+)(,([0-9]+))?}(::[A-Z]+)?
        \end{verbatim}
        as an argument to the function findall(), in order to locate 
        all lists in the CSV file}
    \item{Iterates through the results saving the first group as N}
    \item{If there is an M, saves that value as the largest}
    \item{Uses a regular expression -
        \begin{verbatim}
            (?<=\,)(?=\,)|(?<=\}\,)(?=\,)|(?<=\,\,)(?=)
        \end{verbatim}
        as an argument to the sub function, thus replacing all 
        `,,' patterns with the name of the list}
    \item{Saves all the groups as flags in an associative array}
    \item{Makes the list of saved groups presentable and in the same
        format as the list creation}
    \item{Iterates through the results again and removes list creations
        from the headers}
\end{enumerate}
\subsubsection*{Writing to a file} The conversion itself of the CSV file
to the JSON file is done via writing the structure of the JSON file to a buffer
and plugging in the desired contents, this a very trivial and standard
implementation, requiring only to open the file in write mode, creating
each element of the \JS object and promptly writing it to the JSON file.
However, plugging in the contents, in the solution to this problem, the reader
may find, in lines 47-50 and in lines 131-148, code that suggests the usage of
regular expressions to plug the values and lists into the buffer, that is precisely
what happens in the code.\\
Doing so is nothing more than finding a pattern in how the elements of the JSON file
are written, after which we only need to use the re.sub function and thus have a 
buffer with all the JSON information as required.
\subsubsection*{Creating each element of the Object}
To create the object's elements we need to parse each row of the CSV file,
done so with a function in \ref{ex5py},\textit{conv\_csv\_json(content)}, which,
through the use of flags and some temporary data structures, we are able to
either write to the buffer or create a list as a result.
\paragraph*{Flags and Data Structures Used} This function has the following
arguments: \textit{content, headers, and flags}. \textit{Content} contains
a line to be parsed, \textit{header} is the first line of the CSV file with the alterations
previously mention if lists exist, and the \textit{flags} an associative array
containing the minimum amount of elements, the maximum amount of elements,
and the aggregation function to be applied, if these do not exist,
they are to be ignored.\\
The content argument is converted into list format as the `new' data structure,
\textit{tmp\_head} is a copy of the headers variables so we can change the values in it,
without compromising the good functioning of the the program on other rows,
and \textit{tmp\_array} is the data structure that will be used in order to store the values
of lists.\\
This function also uses some flags that assure the proper readability of the code
and efficiency during the loops, namely, \textit{flag} which checks if during the iteration
of the row, a list was found, \textit{flagM} which checks if the upper bound is M or N,
\textit{flagAg} which verifies if after the list is created a function needs to be applied,
and \textit{flagErr} that indicates whether or not an error was found during the reading
of the CSV file. This program also uses \textit{curr\_check} to count the difference
between the size of \textit{tmp\_array}'s lists and M.
\paragraph*{Iterating and Parsing the List}
From line 54 to line 127 of the code \ref{ex5py}, the program will iterate the
contents of \textit{tmp\_head} in search of repeated, sequential elements.\\
When such a pattern is found, the flag variable is updated, the string that is repeated
is stored in the \textit{test} variable, \textit{tmp\_array} is updated to include \textit{test} as a
key and a list associated to that key, finally, the \textit{flags} argument is processed.\\
Now that all states are set, the program can begin to create the list,
which is done via the successive removal of elements until test is no longer
in \textit{tmp\_head}. By choice, the program only accepts integers as list elements,
otherwise it will raise an error by updating the error flag.\\
However, if the M Flag is set to true, there is a possibility that the element
is a NULL string, in which case we must verify if it is so from:
$$N <= el <= M$$
When, finally, we have no instances of \textit{test} in \textit{tmp\_head}, we can reset the flags,
insert the resulting list to the content data structure new, and reinsert test
into \textit{tmp\_head}.\\
Having done so, we need only continue iterating through the list.
\paragraph*{Using Aggregation Functions}
After a list is fully created, the program only needs to use that list as
an argument to another previously defined function. We chose that it only
made sense to allow for SUM, COUNT, AVG, MAX and MIN, easy to implement
aggregation functions from SQL. In order to ease this process, we used the
built-in python function \textit{eval(string)} to perform these procedures.
\subsection{Testing the code}
In view of proving the proper functioning of the program, some exemplifying tests were
used.

\subsubsection*{Inputs}
\begin{itemize}
    \item The following input was a CSV `database' that one of the Co-Authors
        of this report used in order to coordinate preferences for group and individual tasks
        in an association's department. In order to protect the identities of the
        people in the `database', the names will be replaced with identifying
        numbers.
    \lstinputlisting[label={dataCSV},
    caption=Database Input\ref{dataJSON}]{data.csv}
    Such that 0 represents no interest in the indexed task, 1 represents
    interest, and 2 meaning increased interest.
\item The following test, however is a more generic input that tests 
    variable size lists.
    \lstinputlisting[label={alunosCSV},
    caption=Students input\ref{alunosJSON}]{alunos.csv}
\item The final test consolidates all the previous tests, having both
    varying sized lists, full lists, and aggregation functions over
    both of these forms of functions.
    \lstinputlisting[label={alunos1CSV},
    caption=Students with averages input\ref{alunos1JSON}]{alunos1.csv}
\end{itemize}
\subsubsection*{Outputs}
The program works as expected as can be seen in the output to the
previously defined inputs. \\ The outputs are as follows:
\lstinputlisting[label={dataJSON},
                 caption=Database output\ref{dataCSV}]{data.json}
\lstinputlisting[label={alunosJSON},
                 caption=Students output\ref{alunosCSV}]{alunos.json}
\lstinputlisting[label={alunos1JSON},
                 caption=Students average output\ref{alunos1CSV}]{alunos1.json}
\subsection{Preprocessing XL files}
Throughout this report it was mentioned that our project would intend to 
perform efficient conversions of Excel Files to CSV files, a conversion that
at first glance seems trivial, however it was unanimously decided it would be a
good idea to not go ahead with the development of a preprocessing component to this
program. This decision will be explained in a following section \ref{section:XLCOMP}
\subsubsection*{How it can be done} If one wishes to convert an Excel file into a
\CSV file, one would need to find a way to access the XML files that constitute
any XL file, normally this can be done via renaming the XL file so it's extension
is `.zip', this can be done with a python script that uses two `os' functions:
\begin{itemize}
    \item \verb|os.path.splitext()|
    \item \verb|os.rename()|
\end{itemize}
Now that one has access to the XML files, we are going to use two of them:
\begin{itemize}
    \item \verb|./xl/worksheets/sheet1.xml|
    \item \verb|./xl/sharedStrings.xml|
\end{itemize}
The keen user can tell that both these files are very notorious since there
are some characteristics and rules, such that:
\begin{enumerate}
    \item Any sequence of digits/numerical values are stored in the worksheets.xml
        file;
    \item Any String is located in the sharedStrings.xml file;
    \begin{enumerate} \item These strings are stored in worksheets.xml as indexes \end{enumerate}
\end{enumerate}
In which case, preprocessing XL files seems to be nothing more than the use of
some regular expressions, such as one that finds the location and value of
each cell and stores that as key and value in an associative array.\\ After which
one would iterate through the sharedStrings file, use regex to save the values
via tags, and replace the indexes in the first dictionary with the strings.
\subsubsection*{Complications and why it was not achieved} \label{section:XLCOMP}
Even though this was attempted it was scrapped as finding a solution to
the problem of recognising whether or not a digit in the sheet file is an
index or a numerical value is of extreme difficulty.\\
Thus we realised this task could only be done via either an intelligent system or
access to Excel's source code. 
\\  For such a reason this idea was put on hold and it was decided to
not implement it within the scope of this project.
\section{Conclusion} \label{conclusion}
This project aptly tested understanding of Python, knowledge of regular expressions,
our creativity, our teamwork, and, with the writing of this document,
our understanding of what we accomplished and what we could've done to improve it.\\
Indeed, the reader may find some issues in our code \ref{ex5py}, namely, as we see it,
how unreadable some segments of the code are due to how verbose and compact they are,
particularly the segments of code where Lists are being processed, despite the code being
well commented, in hopes of lightening the effects of such a `flaw'.\\
However, even though we accomplished what we set out to achieve with what was proposed for the
project, as was mentioned in \ref{section:XLCOMP} the last section before this conclusion,
we were not able to implement preprocessing of XL files in our project.
Which is understandable considering the time frame we had to operate under and
the requirements such a task really had, however, of course, it is an important analysis to make,
knowing that preprocessing is a very important requirement, it is, indeed, an important aspect
that can be worked on in the future. Provided there is time and resources to understand in depth
how Excel stores and loads data. Not only this, but perhaps with an enhancement to the readability
of the code, this could be a useful piece of software, as was shown to be in the data example
\ref{dataCSV} \ref{dataJSON}.\\
Having created a program that correctly converts the required CSV file format
into a JSON file format using regular expressions, python, and good programming practices, and
by also ellucidating on how complex some seemingly trivial tasks can be,
we believe that this project was a major success, having far exceeded our expectations.


\chapter{Appendix} \label{chap:code}
\section{Code}
\lstinputlisting[caption={Source Code for the Project's Solution},
                 style=custompy,
                 label={ex5py}
                ]{ex5.py}
\bibliography{mybib}{}
\bibliographystyle{plain}
\end{document}

